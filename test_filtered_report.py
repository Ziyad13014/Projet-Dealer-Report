#!/usr/bin/env python3
"""Test de gÃ©nÃ©ration du rapport HTML avec filtres"""

import os
import sys
import pandas as pd
from dotenv import load_dotenv

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
load_dotenv()

def test_filtered_html_generation():
    try:
        # Lire les donnÃ©es CSV existantes
        csv_path = "reports/spider_vision_overview_20250909_103512.csv"
        if not os.path.exists(csv_path):
            print("âŒ Fichier CSV non trouvÃ©")
            return
        
        # Charger les donnÃ©es CSV
        df = pd.read_csv(csv_path)
        data = df.to_dict('records')
        
        print(f"âœ… DonnÃ©es CSV chargÃ©es: {len(data)} retailers")
        
        # GÃ©nÃ©rer le rapport HTML avec filtres
        from cli.services.html_export import HTMLExporter
        
        html_exporter = HTMLExporter()
        html_path = html_exporter.generate_html_report(data, "reports/spider_vision_filtered_report.html")
        
        print(f"âœ… Rapport HTML avec filtres gÃ©nÃ©rÃ©: {html_path}")
        
        # VÃ©rifier que le fichier existe
        if os.path.exists(html_path):
            file_size = os.path.getsize(html_path)
            print(f"âœ… Fichier HTML crÃ©Ã© ({file_size} bytes)")
            print(f"ðŸŒ Ouvrez le fichier: file:///{os.path.abspath(html_path).replace(chr(92), '/')}")
            
            # Compter les statuts
            success_count = len([r for r in data if pd.notna(r.get('domainDealerName')) and 
                               (r.get('crawlProgress', 0) or 0) > 95 and (r.get('crawlSuccessProgress', 0) or 0) > 85])
            warning_count = len([r for r in data if pd.notna(r.get('domainDealerName')) and 
                               ((r.get('crawlProgress', 0) or 0) >= 90 and (r.get('crawlProgress', 0) or 0) <= 95) or
                               ((r.get('crawlSuccessProgress', 0) or 0) >= 80 and (r.get('crawlSuccessProgress', 0) or 0) <= 85)])
            error_count = len([r for r in data if pd.notna(r.get('domainDealerName')) and 
                             ((r.get('crawlProgress', 0) or 0) < 90 or (r.get('crawlSuccessProgress', 0) or 0) < 80)])
            
            print(f"ðŸ“Š RÃ©partition: {success_count} succÃ¨s, {warning_count} warnings, {error_count} erreurs")
            
        else:
            print("âŒ Fichier HTML non crÃ©Ã©")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_filtered_html_generation()
